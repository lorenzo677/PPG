{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089f163",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5668ecb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CUSTOM SAMPLING LAYER\n",
    "# =============================================================================\n",
    "\n",
    "class Sampling(tf.keras.layers.Layer):\n",
    "    def __init__(self, name=None, **kwargs):\n",
    "        super().__init__(name=name)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe1e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Load pre-saved model\n",
    "# =============================================================================\n",
    "\n",
    "LATENT_DIM = 3\n",
    "BETA = 1\n",
    "\n",
    "# different_values_per_sample = np.prod(data.shape[1:])\n",
    "# new_model = tf.keras.models.load_model(f'''/Users/lorenzo/Desktop/PPG/Cells_vae_best\\\n",
    "#                                         _{LATENT_DIM}D_BETA{BETA}.hdf5''',\n",
    "#                                         custom_objects={'Sampling': Sampling})\n",
    "\n",
    "# new_encoder = new_model.get_layer(index=1)\n",
    "# new_decoder = new_model.get_layer(index=2)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# redict with the loaded model\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# use = data  # select between, det (whole data), train, validation, or test\n",
    "# m, lv, c = new_encoder.predict(use)  # means, logvariances, coordinates\n",
    "# recon = new_decoder.predict(c)       # reconstruced sequences\n",
    "# data = np.asarray(db).copy(order='C')\n",
    "\n",
    "# fnn = FaissKNeighbors(k=5)\n",
    "# ips = np.arange(len(data), dtype=int).copy(order='C')\n",
    "# fnn.fit(data, ips)\n",
    "# nns = fnn.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab9fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/lorenzo/Desktop/PPG/db_ppg.pickle', 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "#print(df)\n",
    "\n",
    "age_labels = df['age']\n",
    "bpm_labels = df['bpm']\n",
    "data = np.asarray([ d/np.max(np.abs(d)) for d in df['signal']])\n",
    "\n",
    "train, test, train_age_labels, test_age_labels, train_bpm_labels, test_bpm_labels = train_test_split(data, age_labels, bpm_labels,\n",
    "                                                          test_size=0.20,\n",
    "                                                          random_state=42)\n",
    "validation, test, validation_age_labels, test_age_labels, validation_bpm_labels, test_bpm_labels = train_test_split(test, test_age_labels, test_bpm_labels, \n",
    "                                                          test_size=0.50,\n",
    "                                                          random_state=42)                                                           \n",
    "train = np.expand_dims(train, axis=-1)\n",
    "validation = np.expand_dims(validation, axis=-1)\n",
    "test = np.expand_dims(test, axis=-1)\n",
    "\n",
    "# the data span is [-1, 1] with filler character '-' at -1\n",
    "# 80% train, 10% validation, 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CONVOLUTIONAL NETWORK\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam(1e-3)\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "LATENT_DIM = 3\n",
    "BETA = 1\n",
    "\n",
    "different_values_per_sample = np.prod(data.shape[1:])\n",
    "dilat_rates = [2, 4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CALLBACKS\n",
    "# =============================================================================\n",
    "\n",
    "# es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "#                                      verbose=1, patience=16)\n",
    "\n",
    "checkp = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                            f'''/Users/lorenzo/Desktop/PPG/callbacks/PPG_vae_best_{LATENT_DIM}D_BETA{BETA}.hdf5''',\n",
    "                                            monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                                            save_weights_only=False)\n",
    "\n",
    "logger = tf.keras.callbacks.CSVLogger('/Users/lorenzo/Desktop/PPG/logging/training.log')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# WaveNet-like convolutional ENCODER\n",
    "# =============================================================================\n",
    "\n",
    "# NOTES: using \"valid\" convolution instead of \"causal\" to implement a wave\n",
    "# architecture in both direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31838aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.keras.layers.Input(shape=train.shape[1:], name=\"Encoder_begin\")  # use None for sequences of variable lentgh\n",
    "\n",
    "wave = tf.keras.layers.Conv1D(filters=16, kernel_size=3,\n",
    "                              padding='valid', dilation_rate=1,\n",
    "                              activation=\"elu\",\n",
    "                              kernel_initializer=\"glorot_uniform\")(inp)\n",
    "waves_list = [wave]\n",
    "\n",
    "for i in dilat_rates:\n",
    "    wave = tf.keras.layers.Conv1D(filters=16, kernel_size=3,#\n",
    "                                  padding='valid', dilation_rate=i,\n",
    "                                  activation=\"elu\",\n",
    "                                  kernel_initializer=\"glorot_uniform\")(wave)\n",
    "    waves_list += [wave]\n",
    "\n",
    "waves = tf.keras.layers.concatenate(waves_list, axis=1)\n",
    "\n",
    "waves = tf.keras.layers.Flatten()(waves)\n",
    "latent_means = tf.keras.layers.Dense(LATENT_DIM, name=\"Encoder_end_means\")(waves)\n",
    "latent_logvars = tf.keras.layers.Dense(LATENT_DIM, kernel_initializer = 'zeros', name=\"Encoder_end_logvars\")(waves)\n",
    "\n",
    "latent_space = Sampling(name=\"Encoder_end_space\")([latent_means, latent_logvars])\n",
    "\n",
    "\n",
    "encoder = tf.keras.Model(inputs=[inp], outputs=[latent_means, latent_logvars, latent_space])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Decoder\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "decoder_input = tf.keras.layers.Input(shape=[LATENT_DIM], name=\"Decoder_begin\")\n",
    "mid = tf.keras.layers.Dense(units=np.prod(train.shape[1:]), activation=\"elu\")(decoder_input)\n",
    "mid = tf.keras.layers.Reshape(target_shape=train.shape[1:])(mid)\n",
    "mid = tf.keras.layers.Conv1DTranspose(filters=32, kernel_size=3,\n",
    "                                      padding='same', activation='elu')(mid)\n",
    "\n",
    "for i in dilat_rates[::-1]:\n",
    "    mid = tf.keras.layers.Conv1DTranspose(filters=16, kernel_size=3, dilation_rate=i,\n",
    "                                          padding='same', activation='elu')(mid)\n",
    "mid = tf.keras.layers.Conv1DTranspose(filters=8, kernel_size=3,\n",
    "                                      padding='same', activation='elu')(mid)\n",
    "\n",
    "reconstruction = tf.keras.layers.Conv1DTranspose(\n",
    "                                                filters=1,\n",
    "                                                kernel_size=3, padding='same', name=\"Decoder_end\")(mid)\n",
    "\n",
    "\n",
    "decoder = tf.keras.Model(inputs=[decoder_input], outputs=[reconstruction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Wave-BETA-VAE\n",
    "# =============================================================================\n",
    "\n",
    "latent_m, latent_lv, latent_coordinates = encoder(inp)\n",
    "out = decoder(latent_coordinates)\n",
    "wave_vae = tf.keras.Model(inputs=[inp], outputs=[out])\n",
    "\n",
    "# KL divergence assuming 2 Gaussians and using G1 = N(0, 1) and precomputed log_var\n",
    "latent_loss = -0.5 * K.sum(1 + latent_lv - K.exp(latent_lv) -\\\n",
    "                           K.square(latent_m), axis=-1)\n",
    "\n",
    "wave_vae.add_loss(K.mean(latent_loss)/different_values_per_sample*BETA)\n",
    "wave_vae.compile(loss=\"MSE\", optimizer=opt)  # adding loss for reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd3b52",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "history = wave_vae.fit(train, train, epochs=100, batch_size=4096,\n",
    "                       validation_data=(validation, validation),\n",
    "                       callbacks=[checkp, logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560179c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_clusters(data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(data)\n",
    "    #plt.figure(figsize=(12, 10))\n",
    "    plt.title('0 vs 1 bpm')\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], s=2, alpha=0.7, c=labels, cmap='rainbow')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "    plt.scatter(z_mean[:, 1], z_mean[:, 2], s=2, alpha=0.7, c=labels, cmap='rainbow')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[1]\")\n",
    "    plt.ylabel(\"z[2]\")\n",
    "    plt.title('1 vs 2 bpm')\n",
    "    plt.show()\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 2], s=2, alpha=0.7, c=labels, cmap='rainbow')\n",
    "    plt.colorbar()\n",
    "    plt.title('0 vs 2 bpm')\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[2]\")\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44fd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_clusters(test, test_bpm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17a9ee",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plot_label_clusters(test, test_age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2763f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
